{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5Jgkkr8yQ0mXelol6VOdL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezaafsharniakan/Classificationethod-KNN/blob/main/keras_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FKbzLoZ95ut3",
        "outputId": "772c31e9-7e44-43e0-ea98-523a6cf75721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST (full) dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/100\n",
            "411/411 [==============================] - 14s 31ms/step - loss: 2.2815 - accuracy: 0.1831 - val_loss: 2.2517 - val_accuracy: 0.1142\n",
            "Epoch 2/100\n",
            "411/411 [==============================] - 6s 14ms/step - loss: 2.2216 - accuracy: 0.3642 - val_loss: 2.1930 - val_accuracy: 0.3914\n",
            "Epoch 3/100\n",
            "411/411 [==============================] - 8s 19ms/step - loss: 2.1562 - accuracy: 0.5210 - val_loss: 2.1181 - val_accuracy: 0.6361\n",
            "Epoch 4/100\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 2.0673 - accuracy: 0.5958 - val_loss: 2.0145 - val_accuracy: 0.6478\n",
            "Epoch 5/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 1.9434 - accuracy: 0.6337 - val_loss: 1.8703 - val_accuracy: 0.6191\n",
            "Epoch 6/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 1.7764 - accuracy: 0.6546 - val_loss: 1.6847 - val_accuracy: 0.6609\n",
            "Epoch 7/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 1.5773 - accuracy: 0.6748 - val_loss: 1.4805 - val_accuracy: 0.6919\n",
            "Epoch 8/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 1.3768 - accuracy: 0.7044 - val_loss: 1.2910 - val_accuracy: 0.7001\n",
            "Epoch 9/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 1.2039 - accuracy: 0.7287 - val_loss: 1.1371 - val_accuracy: 0.7412\n",
            "Epoch 10/100\n",
            "411/411 [==============================] - 4s 8ms/step - loss: 1.0675 - accuracy: 0.7529 - val_loss: 1.0175 - val_accuracy: 0.7667\n",
            "Epoch 11/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.9621 - accuracy: 0.7730 - val_loss: 0.9256 - val_accuracy: 0.7817\n",
            "Epoch 12/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.8799 - accuracy: 0.7880 - val_loss: 0.8511 - val_accuracy: 0.8037\n",
            "Epoch 13/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.8138 - accuracy: 0.8023 - val_loss: 0.7914 - val_accuracy: 0.8123\n",
            "Epoch 14/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.7592 - accuracy: 0.8129 - val_loss: 0.7416 - val_accuracy: 0.8201\n",
            "Epoch 15/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.7133 - accuracy: 0.8225 - val_loss: 0.6988 - val_accuracy: 0.8317\n",
            "Epoch 16/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.6740 - accuracy: 0.8306 - val_loss: 0.6624 - val_accuracy: 0.8374\n",
            "Epoch 17/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.6399 - accuracy: 0.8385 - val_loss: 0.6309 - val_accuracy: 0.8418\n",
            "Epoch 18/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.6104 - accuracy: 0.8439 - val_loss: 0.6030 - val_accuracy: 0.8467\n",
            "Epoch 19/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.5845 - accuracy: 0.8500 - val_loss: 0.5786 - val_accuracy: 0.8516\n",
            "Epoch 20/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.5616 - accuracy: 0.8550 - val_loss: 0.5576 - val_accuracy: 0.8547\n",
            "Epoch 21/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.5415 - accuracy: 0.8598 - val_loss: 0.5379 - val_accuracy: 0.8610\n",
            "Epoch 22/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.5235 - accuracy: 0.8631 - val_loss: 0.5211 - val_accuracy: 0.8643\n",
            "Epoch 23/100\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.5074 - accuracy: 0.8666 - val_loss: 0.5062 - val_accuracy: 0.8659\n",
            "Epoch 24/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.4931 - accuracy: 0.8695 - val_loss: 0.4919 - val_accuracy: 0.8705\n",
            "Epoch 25/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.4800 - accuracy: 0.8727 - val_loss: 0.4800 - val_accuracy: 0.8721\n",
            "Epoch 26/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.4682 - accuracy: 0.8753 - val_loss: 0.4689 - val_accuracy: 0.8746\n",
            "Epoch 27/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.4577 - accuracy: 0.8779 - val_loss: 0.4584 - val_accuracy: 0.8763\n",
            "Epoch 28/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.4480 - accuracy: 0.8800 - val_loss: 0.4495 - val_accuracy: 0.8787\n",
            "Epoch 29/100\n",
            "411/411 [==============================] - 5s 11ms/step - loss: 0.4390 - accuracy: 0.8821 - val_loss: 0.4409 - val_accuracy: 0.8800\n",
            "Epoch 30/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.4309 - accuracy: 0.8837 - val_loss: 0.4333 - val_accuracy: 0.8807\n",
            "Epoch 31/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.4234 - accuracy: 0.8854 - val_loss: 0.4257 - val_accuracy: 0.8837\n",
            "Epoch 32/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.4165 - accuracy: 0.8866 - val_loss: 0.4196 - val_accuracy: 0.8852\n",
            "Epoch 33/100\n",
            "411/411 [==============================] - 5s 11ms/step - loss: 0.4101 - accuracy: 0.8881 - val_loss: 0.4135 - val_accuracy: 0.8862\n",
            "Epoch 34/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.4042 - accuracy: 0.8894 - val_loss: 0.4081 - val_accuracy: 0.8870\n",
            "Epoch 35/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3986 - accuracy: 0.8906 - val_loss: 0.4023 - val_accuracy: 0.8887\n",
            "Epoch 36/100\n",
            "411/411 [==============================] - 5s 11ms/step - loss: 0.3936 - accuracy: 0.8918 - val_loss: 0.3977 - val_accuracy: 0.8902\n",
            "Epoch 37/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3888 - accuracy: 0.8929 - val_loss: 0.3929 - val_accuracy: 0.8901\n",
            "Epoch 38/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3842 - accuracy: 0.8940 - val_loss: 0.3890 - val_accuracy: 0.8910\n",
            "Epoch 39/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3801 - accuracy: 0.8944 - val_loss: 0.3847 - val_accuracy: 0.8921\n",
            "Epoch 40/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.3761 - accuracy: 0.8957 - val_loss: 0.3809 - val_accuracy: 0.8937\n",
            "Epoch 41/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3724 - accuracy: 0.8961 - val_loss: 0.3775 - val_accuracy: 0.8943\n",
            "Epoch 42/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.3688 - accuracy: 0.8970 - val_loss: 0.3743 - val_accuracy: 0.8954\n",
            "Epoch 43/100\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3655 - accuracy: 0.8975 - val_loss: 0.3711 - val_accuracy: 0.8958\n",
            "Epoch 44/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3624 - accuracy: 0.8985 - val_loss: 0.3680 - val_accuracy: 0.8963\n",
            "Epoch 45/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3592 - accuracy: 0.8987 - val_loss: 0.3649 - val_accuracy: 0.8967\n",
            "Epoch 46/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.3564 - accuracy: 0.8994 - val_loss: 0.3625 - val_accuracy: 0.8967\n",
            "Epoch 47/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.3536 - accuracy: 0.8997 - val_loss: 0.3600 - val_accuracy: 0.8971\n",
            "Epoch 48/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3510 - accuracy: 0.9006 - val_loss: 0.3575 - val_accuracy: 0.8989\n",
            "Epoch 49/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3485 - accuracy: 0.9011 - val_loss: 0.3548 - val_accuracy: 0.8988\n",
            "Epoch 50/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.3460 - accuracy: 0.9017 - val_loss: 0.3528 - val_accuracy: 0.8997\n",
            "Epoch 51/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3437 - accuracy: 0.9023 - val_loss: 0.3503 - val_accuracy: 0.8999\n",
            "Epoch 52/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3414 - accuracy: 0.9030 - val_loss: 0.3485 - val_accuracy: 0.8998\n",
            "Epoch 53/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.3393 - accuracy: 0.9033 - val_loss: 0.3468 - val_accuracy: 0.9016\n",
            "Epoch 54/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.3372 - accuracy: 0.9040 - val_loss: 0.3443 - val_accuracy: 0.9007\n",
            "Epoch 55/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.3352 - accuracy: 0.9046 - val_loss: 0.3427 - val_accuracy: 0.9015\n",
            "Epoch 56/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3332 - accuracy: 0.9048 - val_loss: 0.3407 - val_accuracy: 0.9021\n",
            "Epoch 57/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.3313 - accuracy: 0.9057 - val_loss: 0.3391 - val_accuracy: 0.9026\n",
            "Epoch 58/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3295 - accuracy: 0.9058 - val_loss: 0.3370 - val_accuracy: 0.9033\n",
            "Epoch 59/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3277 - accuracy: 0.9060 - val_loss: 0.3357 - val_accuracy: 0.9037\n",
            "Epoch 60/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.3259 - accuracy: 0.9064 - val_loss: 0.3337 - val_accuracy: 0.9034\n",
            "Epoch 61/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.3243 - accuracy: 0.9068 - val_loss: 0.3322 - val_accuracy: 0.9042\n",
            "Epoch 62/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3226 - accuracy: 0.9074 - val_loss: 0.3308 - val_accuracy: 0.9049\n",
            "Epoch 63/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3210 - accuracy: 0.9074 - val_loss: 0.3293 - val_accuracy: 0.9051\n",
            "Epoch 64/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.3194 - accuracy: 0.9080 - val_loss: 0.3280 - val_accuracy: 0.9054\n",
            "Epoch 65/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3179 - accuracy: 0.9084 - val_loss: 0.3266 - val_accuracy: 0.9055\n",
            "Epoch 66/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3165 - accuracy: 0.9088 - val_loss: 0.3249 - val_accuracy: 0.9070\n",
            "Epoch 67/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.3150 - accuracy: 0.9093 - val_loss: 0.3237 - val_accuracy: 0.9069\n",
            "Epoch 68/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.3135 - accuracy: 0.9097 - val_loss: 0.3225 - val_accuracy: 0.9073\n",
            "Epoch 69/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3121 - accuracy: 0.9098 - val_loss: 0.3214 - val_accuracy: 0.9078\n",
            "Epoch 70/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3108 - accuracy: 0.9106 - val_loss: 0.3199 - val_accuracy: 0.9080\n",
            "Epoch 71/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.3094 - accuracy: 0.9106 - val_loss: 0.3190 - val_accuracy: 0.9083\n",
            "Epoch 72/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3081 - accuracy: 0.9110 - val_loss: 0.3176 - val_accuracy: 0.9092\n",
            "Epoch 73/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3068 - accuracy: 0.9118 - val_loss: 0.3166 - val_accuracy: 0.9089\n",
            "Epoch 74/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.3056 - accuracy: 0.9120 - val_loss: 0.3153 - val_accuracy: 0.9093\n",
            "Epoch 75/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.3043 - accuracy: 0.9121 - val_loss: 0.3143 - val_accuracy: 0.9093\n",
            "Epoch 76/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3031 - accuracy: 0.9129 - val_loss: 0.3129 - val_accuracy: 0.9104\n",
            "Epoch 77/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.3019 - accuracy: 0.9135 - val_loss: 0.3117 - val_accuracy: 0.9102\n",
            "Epoch 78/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.3007 - accuracy: 0.9130 - val_loss: 0.3110 - val_accuracy: 0.9109\n",
            "Epoch 79/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2995 - accuracy: 0.9135 - val_loss: 0.3099 - val_accuracy: 0.9114\n",
            "Epoch 80/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2984 - accuracy: 0.9142 - val_loss: 0.3089 - val_accuracy: 0.9120\n",
            "Epoch 81/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.2972 - accuracy: 0.9144 - val_loss: 0.3084 - val_accuracy: 0.9115\n",
            "Epoch 82/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.2962 - accuracy: 0.9150 - val_loss: 0.3067 - val_accuracy: 0.9126\n",
            "Epoch 83/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2951 - accuracy: 0.9150 - val_loss: 0.3055 - val_accuracy: 0.9130\n",
            "Epoch 84/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2940 - accuracy: 0.9154 - val_loss: 0.3047 - val_accuracy: 0.9125\n",
            "Epoch 85/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.2929 - accuracy: 0.9155 - val_loss: 0.3038 - val_accuracy: 0.9131\n",
            "Epoch 86/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2918 - accuracy: 0.9162 - val_loss: 0.3030 - val_accuracy: 0.9131\n",
            "Epoch 87/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2907 - accuracy: 0.9165 - val_loss: 0.3018 - val_accuracy: 0.9133\n",
            "Epoch 88/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.2898 - accuracy: 0.9163 - val_loss: 0.3014 - val_accuracy: 0.9138\n",
            "Epoch 89/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.2888 - accuracy: 0.9168 - val_loss: 0.3000 - val_accuracy: 0.9138\n",
            "Epoch 90/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2879 - accuracy: 0.9174 - val_loss: 0.2989 - val_accuracy: 0.9145\n",
            "Epoch 91/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2868 - accuracy: 0.9177 - val_loss: 0.2985 - val_accuracy: 0.9140\n",
            "Epoch 92/100\n",
            "411/411 [==============================] - 5s 11ms/step - loss: 0.2859 - accuracy: 0.9176 - val_loss: 0.2975 - val_accuracy: 0.9155\n",
            "Epoch 93/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2849 - accuracy: 0.9183 - val_loss: 0.2963 - val_accuracy: 0.9156\n",
            "Epoch 94/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2839 - accuracy: 0.9188 - val_loss: 0.2956 - val_accuracy: 0.9150\n",
            "Epoch 95/100\n",
            "411/411 [==============================] - 4s 10ms/step - loss: 0.2830 - accuracy: 0.9185 - val_loss: 0.2949 - val_accuracy: 0.9160\n",
            "Epoch 96/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.2820 - accuracy: 0.9189 - val_loss: 0.2938 - val_accuracy: 0.9159\n",
            "Epoch 97/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2811 - accuracy: 0.9189 - val_loss: 0.2931 - val_accuracy: 0.9164\n",
            "Epoch 98/100\n",
            "411/411 [==============================] - 4s 9ms/step - loss: 0.2803 - accuracy: 0.9192 - val_loss: 0.2922 - val_accuracy: 0.9163\n",
            "Epoch 99/100\n",
            "411/411 [==============================] - 4s 11ms/step - loss: 0.2793 - accuracy: 0.9199 - val_loss: 0.2916 - val_accuracy: 0.9161\n",
            "Epoch 100/100\n",
            "411/411 [==============================] - 3s 8ms/step - loss: 0.2784 - accuracy: 0.9200 - val_loss: 0.2910 - val_accuracy: 0.9156\n",
            "[INFO] evaluating network...\n",
            "137/137 [==============================] - 1s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96      1754\n",
            "           1       0.94      0.97      0.96      1899\n",
            "           2       0.92      0.89      0.91      1779\n",
            "           3       0.92      0.87      0.89      1763\n",
            "           4       0.91      0.92      0.91      1612\n",
            "           5       0.88      0.86      0.87      1622\n",
            "           6       0.93      0.95      0.94      1743\n",
            "           7       0.94      0.93      0.93      1814\n",
            "           8       0.88      0.90      0.89      1765\n",
            "           9       0.88      0.90      0.89      1749\n",
            "\n",
            "    accuracy                           0.92     17500\n",
            "   macro avg       0.91      0.91      0.91     17500\n",
            "weighted avg       0.92      0.92      0.92     17500\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8c0ee9f7896e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss and Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# import the necessary packages\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import SGD\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "# construct the argument parse and parse the arguments\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-o\", \"--output\", required=True,\n",
        "#                 help=\"path to the output loss/accuracy plot\")\n",
        "\n",
        "# args = vars(ap.parse_args())\n",
        "\n",
        "# grab the MNIST dataset (if this is your first time running this\n",
        "# script, the download may take a minute -- the 55MB MNIST dataset\n",
        "# will be downloaded)\n",
        "print(\"[INFO] loading MNIST (full) dataset...\")\n",
        "dataset = datasets.fetch_openml('mnist_784')\n",
        "\n",
        "# scale the raw pixel intensities to the range [0, 1.0], then\n",
        "# construct the training and testing splits\n",
        "data = dataset.data.astype(\"float\") / 255.0\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,dataset.target, test_size=0.25)\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "# define the 784-256-128-10 architecture using Keras\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"sigmoid\"))\n",
        "model.add(Dense(128, activation=\"sigmoid\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "# train the model using SGD\n",
        "print(\"[INFO] training network...\")\n",
        "sgd = SGD(0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,metrics=[\"accuracy\"])\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY),epochs=100, batch_size=128)\n",
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=128)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "                            predictions.argmax(axis=1),\n",
        "                            target_names=[str(x) for x in lb.classes_]))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "# plt.savefig(args[\"output\"])\n",
        "plt.show()"
      ]
    }
  ]
}